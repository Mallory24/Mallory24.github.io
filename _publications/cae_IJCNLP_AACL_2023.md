---
title: "Implicit Affordance Acquisition via Causal Action-Effect Modeling in the Video Domain"
collection: publications
permalink: publication/cae_IJCNLP_AACL_2023
excerpt: '**Hsiu-Yu Yang** and Carina Silberer'
date: 2023-11-01
venue: 'The 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL)'
paperurl: 'https://arxiv.org/abs/2312.11345'

[//]: # (citation: 'Your Name, You. &#40;2009&#41;. &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1&#40;1&#41;.')
---
Affordance knowledge is a fundamental aspect of commonsense knowledge. Recent findings indicate that world knowledge emerges through large-scale self-supervised pretraining, motivating our exploration of acquiring affordance knowledge from the visual domain. To this end, we augment an existing instructional video resource to create the new Causal Action-Effect (CAE) dataset and design two novel pretraining tasks -- Masked Action Modeling (MAM) and Masked Effect Modeling (MEM) -- promoting the acquisition of two affordance properties in models: behavior and entity equivalence, respectively. We empirically demonstrate the effectiveness of our proposed methods in learning affordance properties. Furthermore, we show that a model pretrained on both tasks outperforms a strong image-based visual-linguistic foundation model (FLAVA) as well as pure linguistic models on a zero-shot physical reasoning probing task.
[//]: # ([Download paper here]&#40;http://academicpages.github.io/files/paper1.pdf&#41;)

[//]: # (Recommended citation: Your Name, You. &#40;2009&#41;. "Paper Title Number 1." <i>Journal 1</i>. 1&#40;1&#41;.)